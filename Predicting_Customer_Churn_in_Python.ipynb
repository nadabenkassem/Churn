{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imJr5uuZOp3-"
      },
      "source": [
        "\n",
        "<h1><center>Marketing Analytics: Predicting Customer Churn in Python</center></h1>\n",
        "\n",
        "\n",
        "<h4>About this Project</h4>\n",
        "Churn is when a customer stops doing business or ends a relationship with a company. It’s a common problem across a variety of industries, from telecommunications to cable TV to SaaS, and a company that can predict churn can take proactive action to retain valuable customers and get ahead of the competition. This course will provide you a roadmap to create your own customer churn models. You’ll learn how to explore and visualize your data, prepare it for modeling, make predictions using machine learning, and communicate important, actionable insights to stakeholders. By the end of the course, you’ll become comfortable using the pandas library for data analysis and the scikit-learn library for machine learning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ObvYBkcOp4F"
      },
      "source": [
        "<h1>Table of contents</h1>\n",
        "\n",
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "    <ol>\n",
        "        <li><a href=\"#exploratory_data_analysis\">Exploratory Data Analysis</a></li>\n",
        "        <li><a href=\"#preprocessing_for_churn_modeling\">Preprocessing for Churn Modeling</a></li>\n",
        "        <li><a href=\"#churn_prediction\">Churn Prediction</a></li>\n",
        "        <li><a href=\"#model_tuning\">Model Tuning</a></li>\n",
        "    </ol>\n",
        "</div>\n",
        "<br>\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsEDOpogOp4G"
      },
      "source": [
        "<h2 id=\"exploratory_data_analysis\">Exploratory Data Analysis</h2>\n",
        "There are many examples and use cases of customer churn for example cancelled a service that is under contract.\n",
        "The dataset have 483 Churners and 2850 Non-Churners.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HsCwiE-Op4H"
      },
      "source": [
        "<h3>Grouping and summarizing data</h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue9jGSmjOp4H"
      },
      "source": [
        "<h4>Summary statistics for both classes</h4>\n",
        "Here, a DataFrame df is grouped by a column 'x', and then the standard deviation is calculated across all columns of df for each value of 'x'. The .groupby() method is incredibly useful when you want to investigate specific columns of your dataset. Here, you're going to explore the 'Churn' column further to see if there are differences between churners and non-churners. A subset version of the telco DataFrame, consisting of the columns 'Churn', 'CustServ_Calls', and 'Vmail_Message' is available in your workspace.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJrh_aa_Op4H"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt # plotting\n",
        "import numpy as np # linear algebra\n",
        "import os # accessing directory structure\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZcxJ9FrOp4I"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('TelcoChurnDataset.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xfms-pl_Op4J"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WYEhuv2Op4J"
      },
      "outputs": [],
      "source": [
        "# Group telco by 'Churn' and compute the mean\n",
        "print(telco.groupby(['Churn']).mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsA8sDt7Op4K"
      },
      "outputs": [],
      "source": [
        "# Adapt your code to compute the standard deviation\n",
        "print(telco.groupby(['Churn']).std())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNM2pLbjOp4K"
      },
      "source": [
        "Churners make more customer service calls than non-churners."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8IK_imCOp4L"
      },
      "source": [
        "<h3>Churn by State</h3>\n",
        "When dealing with customer data, geographic regions may play an important part in determining whether a customer will cancel their service or not. You may have noticed that there is a 'State' column in the dataset. In this exercise, you'll group 'State' and 'Churn' to count the number of churners and non-churners by state. For example, if you wanted to group by x and aggregate by y, you could use .groupby() as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gifn-rTpOp4L"
      },
      "outputs": [],
      "source": [
        "# Count the number of churners and non-churners by State\n",
        "print(telco.groupby('State')['Churn'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYeDVbbIOp4L"
      },
      "source": [
        "California (CA) has 25 non-churners and 9 churners.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIbzRZaEOp4M"
      },
      "source": [
        "<h3>Exploring your data using visualizations</h3>\n",
        "The 'Account_Length' feature was normally distributed. Let's now visualize the distributions of the following features using seaborn's distribution plot:\n",
        "\n",
        "'Day_Mins'\n",
        "'Eve_Mins'\n",
        "'Night_Mins'\n",
        "'Intl_Mins'\n",
        "To create a feature's distribution plot, pass it in as an argument to sns.distplot(). The Telco dataset is available to you as a DataFrame called telco.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzcd2ERcOp4M"
      },
      "source": [
        "Visualize the distribution of 'Day_Mins'.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ws2NYyUuOp4M"
      },
      "outputs": [],
      "source": [
        "# Import matplotlib and seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Visualize the distribution of 'Day_Mins'\n",
        "sns.distplot(telco['Day_Mins'])\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjAlqvv7Op4N"
      },
      "source": [
        "Update your code to visualize the distribution of 'Eve_Mins'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzVPo395Op4N"
      },
      "outputs": [],
      "source": [
        "# Import matplotlib and seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Visualize the distribution of 'Eve_Mins'\n",
        "sns.distplot(telco['Eve_Mins'])\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsceb81COp4N"
      },
      "source": [
        "Update your code to visualize the distribution of 'Night_Mins'.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5CeQmR-Op4O"
      },
      "outputs": [],
      "source": [
        "# Import matplotlib and seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Visualize the distribution of 'Night_Mins'\n",
        "sns.distplot(telco['Night_Mins'])\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKFW8Z27Op4O"
      },
      "source": [
        "Update your code to visualize the distribution of 'Intl_Mins'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbW5PBwROp4O"
      },
      "outputs": [],
      "source": [
        "# Import matplotlib and seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Visualize the distribution of 'Intl_Mins'\n",
        "sns.distplot(telco['Intl_Mins'])\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgQ-RKa2Op4O"
      },
      "source": [
        "<h4>Customer service calls and churn</h4>\n",
        "You've already seen that there's not much of a difference in account lengths between churners and non-churners, but that there is a difference in the number of customer service calls left by churners.\n",
        "\n",
        "Let's now visualize this difference using a box plot and incorporate other features of interest - do customers who have international plans make more customer service calls? Or do they tend to churn more? How about voicemail plans? Let's find out!\n",
        "\n",
        "Recall the syntax for creating a box plot using seaborn:\n",
        "\n",
        "sns.boxplot(x = \"X-axis variable\",\n",
        "            y = \"Y-axis variable\",\n",
        "            data = DataFrame)\n",
        "If you want to remove outliers, you can specify the additional parameter sym=\"\", and you can add a third variable using hue.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cj2-n0K2Op4P"
      },
      "source": [
        "Create a box plot with 'Churn' on the x-axis and 'CustServ_Calls' on the y-axis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hZ_uouQOp4P"
      },
      "outputs": [],
      "source": [
        "# Import matplotlib and seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Create the box plot\n",
        "sns.boxplot(x = 'Churn',\n",
        "          y = 'CustServ_Calls',\n",
        "          data = telco)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsJdGvmuOp4P"
      },
      "source": [
        "There is a very noticeable difference here between churners and non-churners! Now, remove the outliers from the box plot.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEkGC6rAOp4P"
      },
      "outputs": [],
      "source": [
        "# Import matplotlib and seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Create the box plot\n",
        "sns.boxplot(x = 'Churn',\n",
        "            y = 'CustServ_Calls',\n",
        "            data = telco,\n",
        "            sym = \"\")\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA0krJbVOp4Q"
      },
      "source": [
        "Add a third variable to this plot - 'Vmail_Plan' - to visualize whether or not having a voice mail plan affects the number of customer service calls or churn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EK1xGj3pOp4Q"
      },
      "outputs": [],
      "source": [
        "# Import matplotlib and seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Add \"Vmail_Plan\" as a third variable\n",
        "sns.boxplot(x = 'Churn',\n",
        "            y = 'CustServ_Calls',\n",
        "            data = telco,\n",
        "            sym = \"\",\n",
        "            hue = 'Vmail_Plan')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNZWoSz9Op4Q"
      },
      "source": [
        "Not much of a difference there. Update your code so that the third variable is 'Intl_Plan' instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkbzWColOp4Q"
      },
      "outputs": [],
      "source": [
        "# Import matplotlib and seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Add \"Intl_Plan\" as a third variable\n",
        "sns.boxplot(x = 'Churn',\n",
        "            y = 'CustServ_Calls',\n",
        "            data = telco,\n",
        "            sym = \"\",\n",
        "            hue = \"Intl_Plan\")\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHg6A6KEOp4Q"
      },
      "source": [
        "\n",
        "<h2 id=\"preprocessing_for_churn_modeling\">Preprocessing for Churn Modeling</h2>\n",
        "\n",
        "<h3>Data preparation</h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzNyNUIJOp4R"
      },
      "source": [
        "<h2 id=\"reading_data\">Reading the data in</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlE4J8s5Op4R"
      },
      "source": [
        "<h4>Identifying features to convert</h4>\n",
        "It is preferable to have features like 'Churn' encoded as 0 and 1 instead of no and yes, so that you can then feed it into machine learning algorithms that only accept numeric values.\n",
        "\n",
        "Besides 'Churn', other features that are of type object can be converted into 0s and 1s.\n",
        "The different data types of telco in the IPython Shell and the ones that are of type object are:\n",
        "Churn, Intl_Plan, Vmail_Plan, State."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLn8vZbVOp4R"
      },
      "source": [
        "<h4>Encoding binary features</h4>\n",
        "Recasting data types is an important part of data preprocessing. In this exercise you will assign the values 1 to 'yes' and 0 to 'no' to the 'Vmail_Plan' and 'Churn' features, respectively.\n",
        "\n",
        "You saw two approaches to doing this in the video - one using pandas, and the other using scikit-learn. For straightforward tasks like this, sticking with pandas is recommended, so that's what we'll do in this exercise. If you're trying to build machine learning pipelines, on the other hand - which is beyond the scope of this course - you can explore using LabelEncoder(). When doing data science, it's important to be aware that there is always more than one way to accomplish a task, and you need to pick the one that is most effective for your application."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "serPhDRnOp4R"
      },
      "outputs": [],
      "source": [
        "# Replace 'no' with 0 and 'yes' with 1 in 'Vmail_Plan'\n",
        "telco['Vmail_Plan'] = telco['Vmail_Plan'].replace({'no':0, 'yes': 1})\n",
        "\n",
        "# Replace 'no' with 0 and 'yes' with 1 in 'Churn'\n",
        "telco['Churn'] = telco['Churn'].replace({'no':0, 'yes': 1})\n",
        "\n",
        "# Print the results to verify\n",
        "print(telco['Vmail_Plan'].head())\n",
        "print(telco['Churn'].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWywn7TOOp4T"
      },
      "source": [
        "<h4>One hot encoding</h4>\n",
        "the 'State' feature can be encoded numerically using the technique of one hot encoding:\n",
        "\n",
        "ohe_part3.png\n",
        "\n",
        "Doing this manually would be quite tedious, especially when you have 50 states and over 3000 customers! Fortunately, pandas has a get_dummies() function which automatically applies one hot encoding over the selected feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSgDPfXhOp4U"
      },
      "outputs": [],
      "source": [
        "# Import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Perform one hot encoding on 'State'\n",
        "telco_state = pd.get_dummies(telco['State'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPeHYdvjOp4V"
      },
      "outputs": [],
      "source": [
        "# Print the head of telco_state\n",
        "print(telco_state.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp7p7OCKOp4V"
      },
      "source": [
        "<h4>Feature scaling</h4>\n",
        "Recall from the video the different scales of the 'Intl_Calls' and 'Night_Mins' features:\n",
        "\n",
        "feature scaling\n",
        "\n",
        "Re-scale them using StandardScaler.\n",
        "\n",
        "The telco DataFrame has been subset to only include the features you want to rescale: 'Intl_Calls' and 'Night_Mins'. To apply StandardScaler, you need to first instantiate it using StandardScaler(), and then apply the fit_transform() method, passing in the DataFrame you want to rescale. You can do this in one line of code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Py3jD2WwOp4W"
      },
      "outputs": [],
      "source": [
        "# Import StandardScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Scale telco\n",
        "telco_scaled = StandardScaler().fit_transform(telco)\n",
        "\n",
        "# Add column names back for readability\n",
        "telco_scaled_df = pd.DataFrame(telco_scaled, columns=[\"Intl_Calls\", \"Night_Mins\"])\n",
        "\n",
        "# Print summary statistics\n",
        "print(telco_scaled_df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Dropping unnecessary features</h4>\n",
        "Some features such as 'Area_Code' and 'Phone' are not useful when it comes to predicting customer churn, and they need to be dropped prior to modeling. The easiest way to do so in Python is using the .drop() method of pandas DataFrames, just as you saw in the video, where 'Soc_Sec' and 'Tax_ID' were dropped:\n",
        "\n",
        "telco.drop(['Soc_Sec', 'Tax_ID'], axis=1)\n",
        "Here, axis=1 indicates that you want to drop 'Soc_Sec' and 'Tax_ID' from the columns.*texte en italique*"
      ],
      "metadata": {
        "id": "YDdSSCUqOvfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the unnecessary features\n",
        "telco = telco.drop(telco[['Area_Code','Phone']], axis=1)"
      ],
      "metadata": {
        "id": "uZhdtnLDPM0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify dropped features\n",
        "print(telco.columns)"
      ],
      "metadata": {
        "id": "LMpoE7eyPVKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Engineering a new column</h4>\n",
        "everaging domain knowledge to engineer new features is an essential part of modeling. This quote from Andrew Ng summarizes the importance of feature engineering:\n",
        "\n",
        "Coming up with features is difficult, time-consuming, requires expert knowledge. \"Applied machine learning\" is basically feature engineering.\n",
        "\n"
      ],
      "metadata": {
        "id": "U0LXkV2HPhYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the new feature\n",
        "telco['Avg_Night_Calls'] = telco['Night_Mins']/ telco['Night_Calls']\n",
        "\n",
        "# Print the first five rows of 'Avg_Night_Calls'\n",
        "print(telco['Avg_Night_Calls'].head())"
      ],
      "metadata": {
        "id": "EI8Asy3kP5lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 id=\"churn_prediction\">Churn Prediction</h2>\n",
        "With your data preprocessed and ready for machine learning, it's time to predict churn! Learn how to build supervised learning machine models in Python using scikit-learn.\n"
      ],
      "metadata": {
        "id": "X7w4zu0qQOgU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWfLQKK2Op4W"
      },
      "source": [
        "<h4>Predicting whether a new customer will churn</h4>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "xTBRqiyzRVzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the classifier\n",
        "clf = LogisticRegression()"
      ],
      "metadata": {
        "id": "3DGAQGmrRZU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the classifier\n",
        "clf.fit(telco[features], telco['Churn'])"
      ],
      "metadata": {
        "id": "_wh19BN7Rd4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the label of new_customer\n",
        "print(clf.predict(new_customer))"
      ],
      "metadata": {
        "id": "cpP7tRLQRiaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Training another scikit-learn model</h4>\n",
        "All sklearn models have .fit() and .predict() methods like the one you used in the previous exercise for the LogisticRegression model. This feature allows you to easily try many different models to see which one gives you the best performance. To get you more confident with using the sklearn API, in this exercise you'll try fitting a DecisionTreeClassifier instead of a LogisticRegression"
      ],
      "metadata": {
        "id": "MFvtAvtRRsPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Instantiate the classifier\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# Fit the classifier\n",
        "clf.fit(telco[features], telco['Churn'])\n",
        "\n",
        "# Predict the label of new_customer\n",
        "print(clf.predict(new_customer))"
      ],
      "metadata": {
        "id": "PZ-IxqCsR-36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Evaluating Model Performance</h4>\n",
        "<h3>Creating training and test sets</h3>\n",
        "Before you create any model, it is important to split your dataset into two: a training set which will be used to build your churn model, and a test set which will be used to validate your model. To do this, you can use the train_test_split() function from sklearn.model_selection."
      ],
      "metadata": {
        "id": "WSUcy9X9SXij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import train_test_split\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "v7sfZxaMSwLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create feature variable\n",
        "X = telco.drop('Churn', axis=1)"
      ],
      "metadata": {
        "id": "8WkfIfHgS0-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create target variable\n",
        "y = telco['Churn']"
      ],
      "metadata": {
        "id": "qdygMWTXS26_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
      ],
      "metadata": {
        "id": "g_CsVkjVS8Ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Check each sets length</h3>\n",
        "Just to make sure train_test_split() worked as you expected it to, check the lengths of X_train and X_test to see how many records are in each set. You can use functions like len() or attributes like .shape to explore this.\n",
        "\n",
        "2333 Train set, 1000 Test set."
      ],
      "metadata": {
        "id": "-UEl7PuWTEVE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Computing accuracy</h3>\n",
        "Having split your data into training and testing sets, you can now fit your model to the training data and then predict the labels of the test data. That's what you'll practice doing in this exercise.\n",
        "\n",
        "So far, you've used Logistic Regression and Decision Trees. Here, you'll use a RandomForestClassifier, which you can think of as an ensemble of Decision Trees that generally outperforms a single Decision Tree.\n",
        "\n",
        "Your work in the previous exercises has carried over, and the training and test sets are available in the variables X_train, X_test, y_train, and y_test."
      ],
      "metadata": {
        "id": "qLCIK4LtUqjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Instantiate the classifier\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "# Fit to the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Compute accuracy\n",
        "print(clf.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "PiZDmwl6U4hG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Model Metrics</h4>\n",
        "<h3>Confusion matrix</h3>\n",
        "Using scikit-learn's confusion_matrix() function, you can easily create your classifier's confusion matrix and gain a more nuanced understanding of its performance. It takes in two arguments: The actual labels of your test set - y_test - and your predicted labels.\n",
        "\n",
        "The predicted labels of your Random Forest classifier from the previous exercise are stored in y_pred and were computed as follows:\n",
        "\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "1c2QaVaRVCFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "eiWCGN7SVTsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the confusion matrix\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "x4nYrHwXVW3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Varying training set size</h3>\n",
        "The size of your training and testing sets influences model performance. Models learn better when they have more training data. However, there's a risk that they overfit to the training data and don't generalize well to new data, so in order to properly evaluate the model's ability to generalize, you need enough testing data. As a result, there is a important balance and trade-off involved between how much you use for training and how much you hold for testing.\n",
        "\n",
        "So far, you've used 70% for training and 30% for testing. Let's now use 80% of the data for training and evaluate how that changes the model's performance."
      ],
      "metadata": {
        "id": "PBQeWf0DVqnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create feature variable\n",
        "X = telco.drop('Churn', axis=1)\n",
        "\n",
        "# Create target variable\n",
        "y = telco['Churn']\n",
        "\n",
        "# Create training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "ZFCAMO7dV2dm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Instantiate the classifier\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "# Fit to the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels of the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Import confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Print confusion matrix\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "ARnn1D5rWCP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This classifier has a higher precision than the previous classifier.\n"
      ],
      "metadata": {
        "id": "Rcsem_7aWHjM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Computing precision and recall</h3>\n",
        "The sklearn.metrics submodule has many functions that allow you to easily calculate interesting metrics. So far, you've calculated precision and recall by hand - this is important while you develop your intuition for both these metrics.\n",
        "\n",
        "In practice, once you do, you can leverage the precision_score and recall_score functions that automatically compute precision and recall, respectively. Both work similarly to other functions in sklearn.metrics - they accept 2 arguments: the first is the actual labels (y_test), and the second is the predicted labels (y_pred).\n",
        "\n",
        "Let's now try a training size of 90%."
      ],
      "metadata": {
        "id": "67_RBdLgWMkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create feature variable\n",
        "X = telco.drop('Churn', axis=1)\n",
        "\n",
        "# Create target variable\n",
        "y = telco['Churn']\n",
        "\n",
        "# Create training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
        "\n",
        "# Import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Instantiate the classifier\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "# Fit to the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels of the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Import precision_score\n",
        "from sklearn.metrics import precision_score"
      ],
      "metadata": {
        "id": "lceVm2qlWXyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the precision\n",
        "print(precision_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "A-5JwoWeWrEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create feature variable\n",
        "X = telco.drop('Churn', axis=1)\n",
        "\n",
        "# Create target variable\n",
        "y = telco['Churn']\n",
        "\n",
        "# Create training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
        "\n",
        "# Import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Instantiate the classifier\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "# Fit to the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels of the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Import recall_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "# Print the recall\n",
        "print(recall_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "oMSYrXJsW3a4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Other model metrics</h4>\n",
        "<h3>ROC curve</h3>\n",
        "Let's now create an ROC curve for our random forest classifier. The first step is to calculate the predicted probabilities output by the classifier for each label using its .predict_proba() method. Then, you can use the roc_curve function from sklearn.metrics to compute the false positive rate and true positive rate, which you can then plot using matplotlib.\n",
        "\n",
        "A RandomForestClassifier with a training set size of 70% has been fit to the data and is available in your workspace as clf."
      ],
      "metadata": {
        "id": "9PrmEQaYW_y8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the probabilities\n",
        "y_pred_prob = clf.predict_proba(X_test)[:, 1]"
      ],
      "metadata": {
        "id": "dbc0mPqpXU3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import roc_curve\n",
        "from sklearn.metrics import roc_curve\n",
        "# Calculate the roc metrics\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)"
      ],
      "metadata": {
        "id": "jg3-gYRYXaVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the ROC curve\n",
        "plt.plot(fpr,tpr)\n",
        "\n",
        "# Add labels and diagonal line\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.plot([0, 1], [0, 1], \"k--\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Zoz0MWJfXkL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Area under the curve</h3>\n",
        "The ROC curve from the previous exercise is viewable on the right. Visually, it looks like a well-performing model. Let's quantify this by computing the area under the curve."
      ],
      "metadata": {
        "id": "lW5f2R_FXz2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import roc_auc_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "# Print the AUC\n",
        "print(roc_auc_score(y_test, y_pred_prob))"
      ],
      "metadata": {
        "id": "SQJig62JYCP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Precision-recall curve</h4>\n",
        "Another way to evaluate model performance is using a precision-recall curve, which shows the tradeoff between precision and recall for different thresholds.\n",
        "\n",
        "On the right, a precision-recall curve has been generated. Spend some time studying it and then select the statement below that is not true.\n",
        "Recall is synonymous with specificity, and precision is identical with positive predictive value."
      ],
      "metadata": {
        "id": "-mgPgY1iYNSa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>F1 score</h3>\n",
        "As you've discovered, there's a tradeoff between precision and recall. Both are important metrics, and depending on how the business is trying to model churn, you may want to focus on optimizing one over the other. Often, stakeholders are interested in a single metric that can quantify model performance. The AUC is one metric you can use in these cases, and another is the F1 score, which is calculated as below:\n",
        "\n",
        "2 * (precision * recall) / (precision + recall)\n",
        "The advantage of the F1 score is it incorporates both precision and recall into a single metric, and a high F1 score is a sign of a well-performing model, even in situations where you might have imbalanced classes. In scikit-learn, you can compute the f-1 score using using the f1_score function."
      ],
      "metadata": {
        "id": "_4q5xZ22YksE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the classifier\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "# Fit to the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels of the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Import f1_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Print the F1 score\n",
        "print(f1_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "pBqn4KOOYvzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 id=\"model_tuning\">Model Tuning</h2>\n",
        "Learn how to improve the performance of your models using hyperparameter tuning and gain a better understanding of the drivers of customer churn that you can take back to the business.\n"
      ],
      "metadata": {
        "id": "bQZCNYJdcjil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Tuning your model</h3>\n",
        "<h4>Tuning the number of features</h4>\n",
        "The default hyperparameters used by your models are not optimized for your data. The goal of grid search cross-validation is to identify those hyperparameters that lead to optimal model performance. In the video, you saw how the random forest's n_estimators hyperparameter was tuned. Here, you'll practice tuning the max_features hyperparameter. The cv hyperparameter is set to 3 so that the code executes quickly.\n",
        "A random forest is an ensemble of many decision trees. The n_estimators hyperparameter controls the number of trees to use in the forest, while the max_features hyperparameter controls the number features the random forest should consider when looking for the best split at decision tree.\n",
        "\n",
        "A random forest classifier has been instantiated for you as clf.\n"
      ],
      "metadata": {
        "id": "s_5j8poQY6Ud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Create the hyperparameter grid\n",
        "param_grid = {'max_features': ['auto', 'sqrt', 'log2']}"
      ],
      "metadata": {
        "id": "2UPIoA47ZVoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call GridSearchCV\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=3)\n",
        "\n",
        "# Fit the model\n",
        "grid_search.fit(X, y)\n",
        "# Print the optimal parameters\n",
        "print(grid_search.best_params_)"
      ],
      "metadata": {
        "id": "sakGbVb5ZbB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Tuning other hyperparameters</h4>\n",
        "The power of GridSearchCV really comes into play when you're tuning multiple hyperparameters, as then the algorithm tries out all possible combinations of hyperparameters to identify the best combination. "
      ],
      "metadata": {
        "id": "EifBYxMrZ4ms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Create the hyperparameter grid\n",
        "param_grid = {\"max_depth\": [3, None],\n",
        "              \"max_features\": [1, 3, 10],\n",
        "              \"bootstrap\": [True, False],\n",
        "              \"criterion\": [\"gini\", \"entropy\"]}\n",
        "\n",
        "# Call GridSearchCV\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=3)"
      ],
      "metadata": {
        "id": "ldXKnWy7aEmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(grid_search.best_params_) "
      ],
      "metadata": {
        "id": "iH-lfanvaI7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Randomized search</h4>\n",
        "In the above chunk of code from the previous exercise, you may have noticed that the first line of code did not take much time to run, while the call to .fit() took several seconds to execute.\n",
        "\n",
        "This is because .fit() is what actually performs the grid search, and in our case, it was grid with many different combinations. As the hyperparameter grid gets larger, grid search becomes slower. In order to solve this problem, instead of trying out every single combination of values, we could randomly jump around the grid and try different combinations. There's a small possibility we may miss the best combination, but we would save a lot of time, or be able to tune more hyperparameters in the same amount of time.\n",
        "\n",
        "In scikit-learn, you can do this using RandomizedSearchCV. It has the same API as GridSearchCV, except that you need to specify a parameter distribution that it can sample from instead of specific hyperparameter values. Let's try it out now! The parameter distribution has been set up for you, along with a random forest classifier called clf."
      ],
      "metadata": {
        "id": "7VfB0G4RaOSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import RandomizedSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "metadata": {
        "id": "3--YXdS5abvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the hyperparameter grid\n",
        "param_dist = {\"max_depth\": [3, None],\n",
        "              \"max_features\": randint(1, 11),\n",
        "              \"bootstrap\": [True, False],\n",
        "              \"criterion\": [\"gini\", \"entropy\"]}\n",
        "\n",
        "# Call RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(clf, param_dist)"
      ],
      "metadata": {
        "id": "NVki98gTafn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "random_search.fit(X, y)\n",
        "\n",
        "# Print best parameters\n",
        "print(random_search.best_params_)"
      ],
      "metadata": {
        "id": "Jc-3Ns2Vaghk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Feature importances</h3>\n",
        "<h4>Visualizing feature importances</h4>\n",
        "Your random forest classifier from earlier exercises has been fit to the telco data and is available to you as clf. Let's visualize the feature importances and get a sense for what the drivers of churn are, using matplotlib's barh to create a horizontal bar plot of feature importances."
      ],
      "metadata": {
        "id": "FQYzRR9oaqdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate feature importances\n",
        "importances = clf.feature_importances_\n",
        "\n",
        "# Create plot\n",
        "plt.barh(range(X.shape[1]), importances)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xLe17ovga4oC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Improving the plot</h4>\n",
        "In order to make the plot more readable, we need to do achieve two goals:\n",
        "\n",
        "Re-order the bars in ascending order.\n",
        "Add labels to the plot that correspond to the feature names.\n",
        "To do this, we'll take advantage of NumPy indexing. The .argsort() method sorts an array and returns the indices. We'll use these indices to achieve both goals\n"
      ],
      "metadata": {
        "id": "ZJLEJHNXbBkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort importances\n",
        "sorted_index = np.argsort(importances)\n",
        "\n",
        "# Create labels\n",
        "labels = X.columns[sorted_index]\n",
        "\n",
        "# Clear current plot\n",
        "plt.clf()\n",
        "\n",
        "# Create plot\n",
        "plt.barh(range(X.shape[1]), importances[sorted_index], tick_label=labels)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dt4oh2X5bQ2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Adding new features</h3>\n",
        "<h4>Does model performance improve?</h4>\n",
        "6 new features have been added to the telco DataFrame:\n",
        "\n",
        "Region_Code\n",
        "Cost_Call\n",
        "Total_Charge\n",
        "Total_Minutes\n",
        "Total_Calls\n",
        "Min_Call"
      ],
      "metadata": {
        "id": "e_6hJosCbZto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
      ],
      "metadata": {
        "id": "mI5Ob-82btfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Computing other metrics</h4>\n",
        "In addition to accuracy, let's also compute the F1 score of this new model to get a better picture of model performance.\n",
        "\n",
        "A 70-30 train-test split has already been done for you, and all necessary modules have been imported."
      ],
      "metadata": {
        "id": "vNVyJJY_b0LT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import f1_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Instantiate the classifier\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "# Fit to the data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels of the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Print the F1 score\n",
        "print(f1_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "WKwzwHzgb_3T"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "52d90d3cc821dd0beedd6e719dbdecc722c226b9d90ed1b663c34e1877f1142e"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}